{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from to_verb import *\n",
    "from factuality_nominalizations import *\n",
    "import sys, os, catvar\n",
    "\n",
    "fact_corpus_path = \"resources/unified_factuality\"\n",
    "factuality_dev = os.path.join(fact_corpus_path, \"dev.conll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = lambda b: df_from_table_string(b, col_names=COL_NAMES)\n",
    "dfs=list(loadLineSplitFiles(factuality_dev, ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [' '.join(df['tok']) for df in dfs]\n",
    "tokSents =  [list(df['tok']) for df in dfs]\n",
    "find_nominalizations = lambda df: df[(df['pos'].isin([\"NN\", \"NNS\"])) & (df['factuality']!=\"_\")]\n",
    "count_nominalizations = lambda df: find_nominalizations(df).shape[0]\n",
    "find_non_nominalization = lambda df: df[(df['pos'].isin([\"NN\", \"NNS\"])) & (df['factuality']==\"_\")]\n",
    "count_non_nominalization = lambda df: find_non_nominalizations(df).shape[0]\n",
    "\n",
    "# verbalize using both WordNet and CatVar\n",
    "def get_verb_forms(nn):\n",
    "    wordnet_verbs = convert_pos(nn, WN_NOUN, WN_VERB)\n",
    "    catvar_verbs = catvar.catvariate(nn)\n",
    "    # sort by distance\n",
    "    vrbs = [v for v,w in results_by_edit_distance(nn, wordnet_verbs + catvar_verbs)]\n",
    "    if vrbs:\n",
    "        return vrbs, True\n",
    "    else:\n",
    "        return [nn], False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prompts for qasrl-crowdsourcing variant \n",
    "prompts = [(tokSent, int(nom_row['tok-id']), get_verb_forms(nom_row['tok'])[0])\n",
    "           for tokSent, df in zip(tokSents, dfs) \n",
    "           for i,nom_row in find_nominalizations(df).iterrows()]\n",
    "noms = [p[0][p[1]] for p in prompts]\n",
    "def vis_prompts(prompts):\n",
    "    return dict(enumerate([(' '.join(p[0][p[1]-2:p[1]+2]), p[2]) for p in prompts]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(prompts[:25],  open(\"QANom_prompts_20\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts for MTurk UI nom. identification task\n",
    "prompts_noms = [{\"context\": sent,\n",
    "                 \"intent\": int(nom_row['tok-id']),\n",
    "                 \"noun\": sent.split(\" \")[int(nom_row['tok-id'])],\n",
    "                 \"verb_forms\": ' '.join(verb_forms[:5]),\n",
    "                 \"is_factuality_event\": \"yes\",\n",
    "                 \"is_had_auto_verbs\": \"yes\" if is_had_verbs else \"no\"}\n",
    "           for sent, df in zip(sentences, dfs) \n",
    "           for i,nom_row in find_nominalizations(df).iterrows()\n",
    "           for verb_forms, is_had_verbs in [get_verb_forms(nom_row['tok'])]]\n",
    "prompts_not_noms = [{\"context\": sent,\n",
    "                     \"intent\": int(nom_row['tok-id']),\n",
    "                     \"noun\": sent.split(\" \")[int(nom_row['tok-id'])],\n",
    "                     \"verb_forms\": ' '.join(verb_forms[:5]),\n",
    "                     \"is_factuality_event\": \"no\",\n",
    "                     \"is_had_auto_verbs\": \"yes\" if is_had_verbs else \"no\"}\n",
    "           for sent, df in zip(sentences, dfs) \n",
    "           for i,nom_row in find_non_nominalization(df).iterrows()\n",
    "           for verb_forms, is_had_verbs in [get_verb_forms(nom_row['tok'])]]\n",
    "def vis_prompts(prompts):\n",
    "    return dict(enumerate([(' '.join(p[\"context\"].split()[p[\"intent\"]-2:p[\"intent\"]+2]), p[\"verb_forms\"]) \n",
    "                           for p in prompts[:100]]))\n",
    "\n",
    "# noms = [p[\"context\"][p[\"intent\"]] for p in prompts_noms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = prompts_noms[:30] + prompts_not_noms[2:32]\n",
    "prompts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export prompts to csv (shuffled)\n",
    "# prompt_df = pd.DataFrame(prompts)\n",
    "# prompt_df.sample(frac=1).to_csv(\"nom_identification_prompts.csv\", index_label=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual assessment - bad nom. or verb-form - classified\n",
    "problematic_wn_nomin = {\n",
    "    # question with verb is not natural\n",
    "    32: ('trading activity dwindled', u'act'),\n",
    "    # verb not derivationally related to noun (even though meaning is presevred) - while there is a sutable verb:\n",
    "    4: ('a threat to', u'menace'),\n",
    "    101: ('In anticipation of', u'expect'),\n",
    "    70: ('a turnaround next', u'reverse'),\n",
    "    68: ('million loss for', u'pass'),\n",
    "    71: ('the loss ,', u'pass'),\n",
    "    121: ('a gain from', u'profit'),\n",
    "    184: ('the alliance .', u'align'),\n",
    "    230: ('quarter loss of', u'pass'),\n",
    "    # not the correct source-verb (but same \"root\")\n",
    "    132: ('the revolution that', u'revolutionize'),\n",
    "    # not a nominalization (no verb is suitable)\n",
    "    24: ('these problems are', u'trouble'),\n",
    "    79: ('procurement scandal .', u'scandalise'),\n",
    "    103: ('transition period .', u'point'),\n",
    "    181: ('50th anniversary .', 'anniversary'),\n",
    "    213: ('world events .', u'effect'),\n",
    "    218: ('no problem with', u'trouble'),\n",
    "    # light-verb constructions nouns (e.g. \"effort\" - \"make an effort\" would have worked, but no verb is suitable) \n",
    "    23: ('undercutting efforts to', u'exert'),\n",
    "    38: (\"'s efforts to\", u'exert'),\n",
    "    208: ('those efforts .', u'exert'),\n",
    "    # not a verb!\n",
    "    104: ('new series of', 'series'),\n",
    "    112: ('a deadline StatesWest', 'deadline'),\n",
    "    118: ('a restructuring program', 'restructuring'),\n",
    "    214: ('increasingly terrorism knows', 'terrorism'),\n",
    "    235: ('first salvo in', u'volley'),\n",
    "    # two-word verbs \n",
    "    46: ('massive selloffs ,', u'sell_off'),\n",
    "    48: ('share turnover for', u'turn_over'),\n",
    "    75: ('the layoffs of', u'lay_off')\n",
    "}\n",
    "prb_prompts = {i:p for i,p in enumerate(prompts) if i in problematic_wn_nomin}\n",
    "{i:(' '.join(p[0][p[1]-3:p[1]+3]), p[2]) for i,p in prb_prompts.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth',400)\n",
    "all_prompts=prompts_noms + prompts_not_noms\n",
    "all_prompts_with_verbs = [p for p in all_prompts if p[\"is_had_auto_verbs\"]==\"yes\"]\n",
    "# pd.DataFrame(all_prompts).groupby([\"is_had_auto_verbs\", \"is_factuality_event\"]).apply(lambda df: df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import verb_to_nom\n",
    "reload(verb_to_nom)\n",
    "import pattern.en\n",
    "possible_noms = verb_to_nom.get_all_possible_nominalizations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(possible_noms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf=pd.DataFrame(all_prompts)\n",
    "pdf['in_possible_noms'] = pdf.noun.str.lower().isin(possible_noms)\n",
    "pdf['is_infinitive'] = pdf.noun.str.lower().isin(verb_to_nom.all_wn_verbs)\n",
    "pdf['both_filters_or'] = pdf.in_possible_noms | (pdf.is_had_auto_verbs==\"yes\")\n",
    "pdf['both_filters_and'] = pdf.in_possible_noms & ((pdf.is_had_auto_verbs==\"yes\")|pdf.is_infinitive)\n",
    "pdf.groupby([\"both_filters_or\", \"is_factuality_event\", ]).count()\n",
    "# pdf.groupby([\"is_factuality_event\", \"both_filters_and\"]).apply(lambda p: p.sample(15))\n",
    "# pdf.groupby([\"is_factuality_event\", \"is_had_auto_verbs\"]).count()\n",
    "# pdf[(pdf.is_factuality_event==\"yes\") & (~pdf.in_possible_noms) & (pdf.is_had_auto_verbs==\"yes\")].sample(10)\n",
    "# pdf[(pdf.is_factuality_event==\"no\") & (pdf.both_filters_and) ].sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_prompts=pdf[pdf.both_filters_and][[u'context', u'intent', u'is_factuality_event', u'is_had_auto_verbs',\n",
    "       u'noun', u'verb_forms', u'in_possible_noms']].sample(60)\n",
    "# chosen_prompts.to_csv(\"nom_identification_prompts.csv\", index_label=\"id\")\n",
    "chosen_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[pdf.both_filters_and & (pdf.is_had_auto_verbs==\"no\")]z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring about unified_factuality dataset \n",
    "Investigate the potential to replicate Kenton Lee annotation methodology to gather \"event detection\", but only for nouns. Is it a good way to annotate Nom.Ident. data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_POS = ['NN', 'NNS', 'NNP']\n",
    "from collections import defaultdict\n",
    "pos2predicates = defaultdict(set)\n",
    "df=dfs[1]\n",
    "examples = []\n",
    "for df in dfs:\n",
    "    tokSent = list(df['tok'])\n",
    "    sent = ' '.join(tokSent)\n",
    "    for i,r in df.iterrows():\n",
    "        if r.factuality not in [\"Nan\", \"nan\", \"_\"]:\n",
    "            pos2predicates[r.pos].add(r.lemma)\n",
    "            if r.pos in NN_POS:\n",
    "                examples.append((r.tok, r['tok-id'], sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1956"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr={k:len(v) for k,v in pos2predicates.iteritems()}\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:None'>***hhhh***</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import imp, sys\n",
    "sys.path.append('../myJupyterUtils/')\n",
    "import utils\n",
    "\n",
    "utils.printmd(\"***hhhh***\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
